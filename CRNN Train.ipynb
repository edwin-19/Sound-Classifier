{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/superceed1/anaconda3/envs/py38torch17/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from torchsummaryX import summary\n",
    "from utils import sound_utils\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "learing_rate = 1e-4\n",
    "eps = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-relaxation",
   "metadata": {},
   "source": [
    "# Load and prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suspended-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minus-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavDataset(Dataset):\n",
    "    def __init__(self, wave_list):\n",
    "        super(WavDataset, self).__init__()\n",
    "        self.wav_list = wave_list\n",
    "        self.labels_index = {\n",
    "            'cat': 0,\n",
    "            'dog': 1\n",
    "        }\n",
    "        self.data_path = 'data/cats_dogs/'\n",
    "        self.max_ms = 8000\n",
    "        self.audio_utils = sound_utils.SoundUtil()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.wav_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        wav_file = self.wav_list[index]\n",
    "        wav_file_path = os.path.join(self.data_path, wav_file)\n",
    "        \n",
    "        labels = self.labels_index[wav_file[:3]]\n",
    "        \n",
    "        return self.audio_utils.convert_sound(wav_file_path, is_augment=True), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "macro-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, df, batch_size=64):\n",
    "        super(WavDataModule, self).__init__()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        train_cat = self.df['train_cat'].sample(64, random_state=2021).tolist()\n",
    "        train_dog = self.df[~df['train_dog'].isnull()]['train_dog'].tolist()\n",
    "        train_data = np.concatenate([train_cat, train_dog])\n",
    "        self.train_set = WavDataset(train_data)\n",
    "        \n",
    "        test_data = self.df[(~self.df['test_cat'].isnull()) & (~self.df['test_dog'].isnull())][['test_cat', 'test_dog']].values.ravel()\n",
    "        self.test_set = WavDataset(test_data)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        sampler = RandomSampler(self.train_set)\n",
    "        data_loader = DataLoader(self.train_set, sampler=sampler, batch_size=self.batch_size)\n",
    "        return data_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        sampler = SequentialSampler(self.test_set)\n",
    "        data_loader = DataLoader(self.test_set, sampler=sampler, batch_size=self.batch_size)\n",
    "        return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "circular-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavdata_module = WavDataModule(df, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-circulation",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cardiac-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCRNN(pl.LightningModule):\n",
    "    def __init__(self, is_resnet=False):\n",
    "        super(AudioCRNN, self).__init__()\n",
    "        self.is_resnet = is_resnet\n",
    "        if not self.is_resnet:\n",
    "            self.feautre_extract = nn.Sequential(\n",
    "                nn.Conv2d(2, 32, 3),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ELU(),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.Dropout(0.1),\n",
    "\n",
    "                # Second level\n",
    "                nn.Conv2d(32, 64, 3),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ELU(),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.Dropout(0.1),\n",
    "\n",
    "                # Third Level\n",
    "                nn.Conv2d(64, 128, 3),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ELU(),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.Dropout(0.1)\n",
    "            )\n",
    "\n",
    "            self.recurr = nn.LSTM(128, 64, 2, bidirectional=True, batch_first=True)\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.Linear(128, 2)\n",
    "            )\n",
    "        else:\n",
    "            resnet = torchvision.models.resnet50(pretrained=True)\n",
    "            resnet.conv1 = nn.Conv2d(\n",
    "                2, resnet.conv1.out_channels, \n",
    "                kernel_size=resnet.conv1.kernel_size[0], \n",
    "                stride=resnet.conv1.stride[0], \n",
    "                padding=resnet.conv1.padding[0]\n",
    "            )\n",
    "            in_features = resnet.fc.in_features\n",
    "            layers = list(resnet.children())[:-1]\n",
    "            \n",
    "            self.classifier = nn.Sequential(*layers)\n",
    "            self.decision = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(in_features, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512, 2)\n",
    "            )\n",
    "            self.classifier.add_module(\n",
    "                'decision', self.decision\n",
    "            )\n",
    "            \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.val_acc = Accuracy()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.is_resnet:\n",
    "            x = self.feautre_extract(x)\n",
    "            x = x.reshape(-1, 6 * 84, 128)\n",
    "            x, _ = self.recurr(x)\n",
    "            x = self.classifier(x[:, -1, :])\n",
    "            \n",
    "        else:\n",
    "            x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        spec, labels = batch\n",
    "        logits = self(spec)\n",
    "        return self.loss(logits, labels)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        spec, labels = batch\n",
    "        logits = self(spec)\n",
    "        \n",
    "        val_loss = self.loss(logits, labels)\n",
    "        self.val_acc(logits.argmax(dim=1), labels)\n",
    "        \n",
    "        self.log('val_loss', val_loss, prog_bar=True)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "swedish-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioCRNN(is_resnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "upper-programming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================\n",
      "                   Kernel Shape       Output Shape     Params    Mult-Adds\n",
      "Layer                                                                     \n",
      "0_val_acc         [2, 64, 7, 7]   [2, 64, 32, 344]     6.336k   69.042176M\n",
      "1_val_acc                  [64]   [2, 64, 32, 344]      128.0         64.0\n",
      "2_val_acc                     -   [2, 64, 32, 344]          -            -\n",
      "3_val_acc                     -   [2, 64, 16, 172]          -            -\n",
      "4_val_acc        [64, 64, 1, 1]   [2, 64, 16, 172]     4.096k   11.272192M\n",
      "5_val_acc                  [64]   [2, 64, 16, 172]      128.0         64.0\n",
      "6_val_acc                     -   [2, 64, 16, 172]          -            -\n",
      "7_val_acc        [64, 64, 3, 3]   [2, 64, 16, 172]    36.864k  101.449728M\n",
      "8_val_acc                  [64]   [2, 64, 16, 172]      128.0         64.0\n",
      "9_val_acc                     -   [2, 64, 16, 172]          -            -\n",
      "10_val_acc      [64, 256, 1, 1]  [2, 256, 16, 172]    16.384k   45.088768M\n",
      "11_val_acc                [256]  [2, 256, 16, 172]      512.0        256.0\n",
      "12_val_acc      [64, 256, 1, 1]  [2, 256, 16, 172]    16.384k   45.088768M\n",
      "13_val_acc                [256]  [2, 256, 16, 172]      512.0        256.0\n",
      "14_val_acc                    -  [2, 256, 16, 172]          -            -\n",
      "15_val_acc      [256, 64, 1, 1]   [2, 64, 16, 172]    16.384k   45.088768M\n",
      "16_val_acc                 [64]   [2, 64, 16, 172]      128.0         64.0\n",
      "17_val_acc                    -   [2, 64, 16, 172]          -            -\n",
      "18_val_acc       [64, 64, 3, 3]   [2, 64, 16, 172]    36.864k  101.449728M\n",
      "19_val_acc                 [64]   [2, 64, 16, 172]      128.0         64.0\n",
      "20_val_acc                    -   [2, 64, 16, 172]          -            -\n",
      "21_val_acc      [64, 256, 1, 1]  [2, 256, 16, 172]    16.384k   45.088768M\n",
      "22_val_acc                [256]  [2, 256, 16, 172]      512.0        256.0\n",
      "23_val_acc                    -  [2, 256, 16, 172]          -            -\n",
      "24_val_acc      [256, 64, 1, 1]   [2, 64, 16, 172]    16.384k   45.088768M\n",
      "25_val_acc                 [64]   [2, 64, 16, 172]      128.0         64.0\n",
      "26_val_acc                    -   [2, 64, 16, 172]          -            -\n",
      "27_val_acc       [64, 64, 3, 3]   [2, 64, 16, 172]    36.864k  101.449728M\n",
      "28_val_acc                 [64]   [2, 64, 16, 172]      128.0         64.0\n",
      "29_val_acc                    -   [2, 64, 16, 172]          -            -\n",
      "30_val_acc      [64, 256, 1, 1]  [2, 256, 16, 172]    16.384k   45.088768M\n",
      "31_val_acc                [256]  [2, 256, 16, 172]      512.0        256.0\n",
      "32_val_acc                    -  [2, 256, 16, 172]          -            -\n",
      "33_val_acc     [256, 128, 1, 1]  [2, 128, 16, 172]    32.768k   90.177536M\n",
      "34_val_acc                [128]  [2, 128, 16, 172]      256.0        128.0\n",
      "35_val_acc                    -  [2, 128, 16, 172]          -            -\n",
      "36_val_acc     [128, 128, 3, 3]    [2, 128, 8, 86]   147.456k  101.449728M\n",
      "37_val_acc                [128]    [2, 128, 8, 86]      256.0        128.0\n",
      "38_val_acc                    -    [2, 128, 8, 86]          -            -\n",
      "39_val_acc     [128, 512, 1, 1]    [2, 512, 8, 86]    65.536k   45.088768M\n",
      "40_val_acc                [512]    [2, 512, 8, 86]     1.024k        512.0\n",
      "41_val_acc     [256, 512, 1, 1]    [2, 512, 8, 86]   131.072k   90.177536M\n",
      "42_val_acc                [512]    [2, 512, 8, 86]     1.024k        512.0\n",
      "43_val_acc                    -    [2, 512, 8, 86]          -            -\n",
      "44_val_acc     [512, 128, 1, 1]    [2, 128, 8, 86]    65.536k   45.088768M\n",
      "45_val_acc                [128]    [2, 128, 8, 86]      256.0        128.0\n",
      "46_val_acc                    -    [2, 128, 8, 86]          -            -\n",
      "47_val_acc     [128, 128, 3, 3]    [2, 128, 8, 86]   147.456k  101.449728M\n",
      "48_val_acc                [128]    [2, 128, 8, 86]      256.0        128.0\n",
      "49_val_acc                    -    [2, 128, 8, 86]          -            -\n",
      "50_val_acc     [128, 512, 1, 1]    [2, 512, 8, 86]    65.536k   45.088768M\n",
      "51_val_acc                [512]    [2, 512, 8, 86]     1.024k        512.0\n",
      "52_val_acc                    -    [2, 512, 8, 86]          -            -\n",
      "53_val_acc     [512, 128, 1, 1]    [2, 128, 8, 86]    65.536k   45.088768M\n",
      "54_val_acc                [128]    [2, 128, 8, 86]      256.0        128.0\n",
      "55_val_acc                    -    [2, 128, 8, 86]          -            -\n",
      "56_val_acc     [128, 128, 3, 3]    [2, 128, 8, 86]   147.456k  101.449728M\n",
      "57_val_acc                [128]    [2, 128, 8, 86]      256.0        128.0\n",
      "58_val_acc                    -    [2, 128, 8, 86]          -            -\n",
      "59_val_acc     [128, 512, 1, 1]    [2, 512, 8, 86]    65.536k   45.088768M\n",
      "60_val_acc                [512]    [2, 512, 8, 86]     1.024k        512.0\n",
      "61_val_acc                    -    [2, 512, 8, 86]          -            -\n",
      "62_val_acc     [512, 128, 1, 1]    [2, 128, 8, 86]    65.536k   45.088768M\n",
      "63_val_acc                [128]    [2, 128, 8, 86]      256.0        128.0\n",
      "64_val_acc                    -    [2, 128, 8, 86]          -            -\n",
      "65_val_acc     [128, 128, 3, 3]    [2, 128, 8, 86]   147.456k  101.449728M\n",
      "66_val_acc                [128]    [2, 128, 8, 86]      256.0        128.0\n",
      "67_val_acc                    -    [2, 128, 8, 86]          -            -\n",
      "68_val_acc     [128, 512, 1, 1]    [2, 512, 8, 86]    65.536k   45.088768M\n",
      "69_val_acc                [512]    [2, 512, 8, 86]     1.024k        512.0\n",
      "70_val_acc                    -    [2, 512, 8, 86]          -            -\n",
      "71_val_acc     [512, 256, 1, 1]    [2, 256, 8, 86]   131.072k   90.177536M\n",
      "72_val_acc                [256]    [2, 256, 8, 86]      512.0        256.0\n",
      "73_val_acc                    -    [2, 256, 8, 86]          -            -\n",
      "74_val_acc     [256, 256, 3, 3]    [2, 256, 4, 43]   589.824k  101.449728M\n",
      "75_val_acc                [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "76_val_acc                    -    [2, 256, 4, 43]          -            -\n",
      "77_val_acc    [256, 1024, 1, 1]   [2, 1024, 4, 43]   262.144k   45.088768M\n",
      "78_val_acc               [1024]   [2, 1024, 4, 43]     2.048k       1.024k\n",
      "79_val_acc    [512, 1024, 1, 1]   [2, 1024, 4, 43]   524.288k   90.177536M\n",
      "80_val_acc               [1024]   [2, 1024, 4, 43]     2.048k       1.024k\n",
      "81_val_acc                    -   [2, 1024, 4, 43]          -            -\n",
      "82_val_acc    [1024, 256, 1, 1]    [2, 256, 4, 43]   262.144k   45.088768M\n",
      "83_val_acc                [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "84_val_acc                    -    [2, 256, 4, 43]          -            -\n",
      "85_val_acc     [256, 256, 3, 3]    [2, 256, 4, 43]   589.824k  101.449728M\n",
      "86_val_acc                [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "87_val_acc                    -    [2, 256, 4, 43]          -            -\n",
      "88_val_acc    [256, 1024, 1, 1]   [2, 1024, 4, 43]   262.144k   45.088768M\n",
      "89_val_acc               [1024]   [2, 1024, 4, 43]     2.048k       1.024k\n",
      "90_val_acc                    -   [2, 1024, 4, 43]          -            -\n",
      "91_val_acc    [1024, 256, 1, 1]    [2, 256, 4, 43]   262.144k   45.088768M\n",
      "92_val_acc                [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "93_val_acc                    -    [2, 256, 4, 43]          -            -\n",
      "94_val_acc     [256, 256, 3, 3]    [2, 256, 4, 43]   589.824k  101.449728M\n",
      "95_val_acc                [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "96_val_acc                    -    [2, 256, 4, 43]          -            -\n",
      "97_val_acc    [256, 1024, 1, 1]   [2, 1024, 4, 43]   262.144k   45.088768M\n",
      "98_val_acc               [1024]   [2, 1024, 4, 43]     2.048k       1.024k\n",
      "99_val_acc                    -   [2, 1024, 4, 43]          -            -\n",
      "100_val_acc   [1024, 256, 1, 1]    [2, 256, 4, 43]   262.144k   45.088768M\n",
      "101_val_acc               [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "102_val_acc                   -    [2, 256, 4, 43]          -            -\n",
      "103_val_acc    [256, 256, 3, 3]    [2, 256, 4, 43]   589.824k  101.449728M\n",
      "104_val_acc               [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "105_val_acc                   -    [2, 256, 4, 43]          -            -\n",
      "106_val_acc   [256, 1024, 1, 1]   [2, 1024, 4, 43]   262.144k   45.088768M\n",
      "107_val_acc              [1024]   [2, 1024, 4, 43]     2.048k       1.024k\n",
      "108_val_acc                   -   [2, 1024, 4, 43]          -            -\n",
      "109_val_acc   [1024, 256, 1, 1]    [2, 256, 4, 43]   262.144k   45.088768M\n",
      "110_val_acc               [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "111_val_acc                   -    [2, 256, 4, 43]          -            -\n",
      "112_val_acc    [256, 256, 3, 3]    [2, 256, 4, 43]   589.824k  101.449728M\n",
      "113_val_acc               [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "114_val_acc                   -    [2, 256, 4, 43]          -            -\n",
      "115_val_acc   [256, 1024, 1, 1]   [2, 1024, 4, 43]   262.144k   45.088768M\n",
      "116_val_acc              [1024]   [2, 1024, 4, 43]     2.048k       1.024k\n",
      "117_val_acc                   -   [2, 1024, 4, 43]          -            -\n",
      "118_val_acc   [1024, 256, 1, 1]    [2, 256, 4, 43]   262.144k   45.088768M\n",
      "119_val_acc               [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "120_val_acc                   -    [2, 256, 4, 43]          -            -\n",
      "121_val_acc    [256, 256, 3, 3]    [2, 256, 4, 43]   589.824k  101.449728M\n",
      "122_val_acc               [256]    [2, 256, 4, 43]      512.0        256.0\n",
      "123_val_acc                   -    [2, 256, 4, 43]          -            -\n",
      "124_val_acc   [256, 1024, 1, 1]   [2, 1024, 4, 43]   262.144k   45.088768M\n",
      "125_val_acc              [1024]   [2, 1024, 4, 43]     2.048k       1.024k\n",
      "126_val_acc                   -   [2, 1024, 4, 43]          -            -\n",
      "127_val_acc   [1024, 512, 1, 1]    [2, 512, 4, 43]   524.288k   90.177536M\n",
      "128_val_acc               [512]    [2, 512, 4, 43]     1.024k        512.0\n",
      "129_val_acc                   -    [2, 512, 4, 43]          -            -\n",
      "130_val_acc    [512, 512, 3, 3]    [2, 512, 2, 22]  2.359296M  103.809024M\n",
      "131_val_acc               [512]    [2, 512, 2, 22]     1.024k        512.0\n",
      "132_val_acc                   -    [2, 512, 2, 22]          -            -\n",
      "133_val_acc   [512, 2048, 1, 1]   [2, 2048, 2, 22]  1.048576M   46.137344M\n",
      "134_val_acc              [2048]   [2, 2048, 2, 22]     4.096k       2.048k\n",
      "135_val_acc  [1024, 2048, 1, 1]   [2, 2048, 2, 22]  2.097152M   92.274688M\n",
      "136_val_acc              [2048]   [2, 2048, 2, 22]     4.096k       2.048k\n",
      "137_val_acc                   -   [2, 2048, 2, 22]          -            -\n",
      "138_val_acc   [2048, 512, 1, 1]    [2, 512, 2, 22]  1.048576M   46.137344M\n",
      "139_val_acc               [512]    [2, 512, 2, 22]     1.024k        512.0\n",
      "140_val_acc                   -    [2, 512, 2, 22]          -            -\n",
      "141_val_acc    [512, 512, 3, 3]    [2, 512, 2, 22]  2.359296M  103.809024M\n",
      "142_val_acc               [512]    [2, 512, 2, 22]     1.024k        512.0\n",
      "143_val_acc                   -    [2, 512, 2, 22]          -            -\n",
      "144_val_acc   [512, 2048, 1, 1]   [2, 2048, 2, 22]  1.048576M   46.137344M\n",
      "145_val_acc              [2048]   [2, 2048, 2, 22]     4.096k       2.048k\n",
      "146_val_acc                   -   [2, 2048, 2, 22]          -            -\n",
      "147_val_acc   [2048, 512, 1, 1]    [2, 512, 2, 22]  1.048576M   46.137344M\n",
      "148_val_acc               [512]    [2, 512, 2, 22]     1.024k        512.0\n",
      "149_val_acc                   -    [2, 512, 2, 22]          -            -\n",
      "150_val_acc    [512, 512, 3, 3]    [2, 512, 2, 22]  2.359296M  103.809024M\n",
      "151_val_acc               [512]    [2, 512, 2, 22]     1.024k        512.0\n",
      "152_val_acc                   -    [2, 512, 2, 22]          -            -\n",
      "153_val_acc   [512, 2048, 1, 1]   [2, 2048, 2, 22]  1.048576M   46.137344M\n",
      "154_val_acc              [2048]   [2, 2048, 2, 22]     4.096k       2.048k\n",
      "155_val_acc                   -   [2, 2048, 2, 22]          -            -\n",
      "156_val_acc                   -    [2, 2048, 1, 1]          -            -\n",
      "157_val_acc                   -          [2, 2048]          -            -\n",
      "158_val_acc                   -          [2, 2048]          -            -\n",
      "159_val_acc         [2048, 512]           [2, 512]  1.049088M    1.048576M\n",
      "160_val_acc         [2048, 512]           [2, 512]          -    1.048576M\n",
      "161_val_acc                   -           [2, 512]          -            -\n",
      "162_val_acc                   -           [2, 512]          -            -\n",
      "163_val_acc                   -           [2, 512]          -            -\n",
      "164_val_acc                   -           [2, 512]          -            -\n",
      "165_val_acc            [512, 2]             [2, 2]     1.026k       1.024k\n",
      "166_val_acc            [512, 2]             [2, 2]          -       1.024k\n",
      "--------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params            24.555074M\n",
      "Trainable params        24.555074M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             3.568693184G\n",
      "==========================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_val_acc</th>\n",
       "      <td>[2, 64, 7, 7]</td>\n",
       "      <td>[2, 64, 32, 344]</td>\n",
       "      <td>6336.0</td>\n",
       "      <td>69042176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_val_acc</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[2, 64, 32, 344]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_val_acc</th>\n",
       "      <td>-</td>\n",
       "      <td>[2, 64, 32, 344]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_val_acc</th>\n",
       "      <td>-</td>\n",
       "      <td>[2, 64, 16, 172]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_val_acc</th>\n",
       "      <td>[64, 64, 1, 1]</td>\n",
       "      <td>[2, 64, 16, 172]</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>11272192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162_val_acc</th>\n",
       "      <td>-</td>\n",
       "      <td>[2, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163_val_acc</th>\n",
       "      <td>-</td>\n",
       "      <td>[2, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164_val_acc</th>\n",
       "      <td>-</td>\n",
       "      <td>[2, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165_val_acc</th>\n",
       "      <td>[512, 2]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166_val_acc</th>\n",
       "      <td>[512, 2]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Kernel Shape      Output Shape  Params   Mult-Adds\n",
       "Layer                                                            \n",
       "0_val_acc     [2, 64, 7, 7]  [2, 64, 32, 344]  6336.0  69042176.0\n",
       "1_val_acc              [64]  [2, 64, 32, 344]   128.0        64.0\n",
       "2_val_acc                 -  [2, 64, 32, 344]     NaN         NaN\n",
       "3_val_acc                 -  [2, 64, 16, 172]     NaN         NaN\n",
       "4_val_acc    [64, 64, 1, 1]  [2, 64, 16, 172]  4096.0  11272192.0\n",
       "...                     ...               ...     ...         ...\n",
       "162_val_acc               -          [2, 512]     NaN         NaN\n",
       "163_val_acc               -          [2, 512]     NaN         NaN\n",
       "164_val_acc               -          [2, 512]     NaN         NaN\n",
       "165_val_acc        [512, 2]            [2, 2]  1026.0      1024.0\n",
       "166_val_acc        [512, 2]            [2, 2]     NaN      1024.0\n",
       "\n",
       "[167 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, torch.zeros(2, 2, 64, 688))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-sequence",
   "metadata": {},
   "source": [
    "# Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seven-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = pl.callbacks.EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    min_delta=0.02,\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deluxe-galaxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=epochs, \n",
    "    progress_bar_refresh_rate=20,\n",
    "#     callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sound-continuity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | classifier | Sequential       | 24.6 M\n",
      "1 | decision   | Sequential       | 1.1 M \n",
      "2 | loss       | CrossEntropyLoss | 0     \n",
      "3 | val_acc    | Accuracy         | 0     \n",
      "------------------------------------------------\n",
      "24.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.6 M    Total params\n",
      "98.220    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/superceed1/anaconda3/envs/py38torch17/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/superceed1/anaconda3/envs/py38torch17/lib/python3.8/site-packages/torch/functional.py:515: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore\n",
      "/home/superceed1/anaconda3/envs/py38torch17/lib/python3.8/site-packages/torch/functional.py:515: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore\n",
      "/home/superceed1/anaconda3/envs/py38torch17/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e348c6350884bb5ad8ad1b18b0d0cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, wavdata_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wooden-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.918367326259613, 'val_loss': 0.3337607979774475}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.3337607979774475, 'val_acc': 0.918367326259613}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, wavdata_module.val_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-pharmacy",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hairy-wayne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioCRNN(\n",
       "  (classifier): Sequential(\n",
       "    (0): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (decision): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=512, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decision): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       "  (val_acc): Accuracy()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cellular-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for data, label in wavdata_module.val_dataloader():\n",
    "    logits = model(data.to('cpu'))\n",
    "    preds = F.softmax(logits, dim=-1)\n",
    "    y_pred.append(preds.detach().cpu().numpy().argmax(axis=1))\n",
    "    y_true.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "administrative-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "experienced-surveillance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        49\n",
      "           1       0.96      0.90      0.93        49\n",
      "\n",
      "    accuracy                           0.93        98\n",
      "   macro avg       0.93      0.93      0.93        98\n",
      "weighted avg       0.93      0.93      0.93        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "floppy-rebound",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), fmt='3', annot=True, xticklabels=['cat', 'dog'], yticklabels=['cat', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "technological-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.8587538611150073\n"
     ]
    }
   ],
   "source": [
    "print('MCC: {}'.format(matthews_corrcoef(y_true, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
